---
title: "Computational Intelligence - Assignment 1"
author: "Bruno SÃ¡nchez and Sheena Lang"
date: "`r Sys.Date()`"
output: html_document
---

## Introduction

This is an example of R Markdown.

## Data Collection

```{r}

library(MASS)  
library(caret) 
library(lattice)
library(GGally)


generate_synthetic_data <- function(n_train, n_val, n_test, noise_level = 0.1, hardness = 0.5) {
  set.seed(123)
  
  mu_setosa <- c(5.01, 3.43, 1.46, 0.246)  
  mu_versicolor <- c(5.94, 2.77, 4.26, 1.33)  
  mu_virginica <- c(6.59, 2.97, 5.55, 2.03)

  mu_setosa <- mu_setosa - c(hardness, hardness, hardness, hardness)
  mu_virginica <- mu_virginica + c(hardness, hardness, hardness, hardness) 

  setosa_cov <- matrix(c(
    0.12424898, 0.099216327, 0.016355102, 0.010330612,
    0.09921633, 0.143689796, 0.011697959, 0.009297959,
    0.01635510, 0.011697959, 0.030159184, 0.006069388,
    0.01033061, 0.009297959, 0.006069388, 0.011106122
  ), nrow = 4, byrow = TRUE)

  versicolor_cov <- matrix(c(
    0.26643265, 0.08518367, 0.18289796, 0.05577959,
    0.08518367, 0.09846939, 0.08265306, 0.04120408,
    0.18289796, 0.08265306, 0.22081633, 0.07310204,
    0.05577959, 0.04120408, 0.07310204, 0.03910612
  ), nrow = 4, byrow = TRUE)

  virginica_cov <- matrix(c(
    0.40434286, 0.09376327, 0.30328980, 0.04909388,
    0.09376327, 0.10400408, 0.07137959, 0.04762857,
    0.30328980, 0.07137959, 0.30458776, 0.04882449,
    0.04909388, 0.04762857, 0.04882449, 0.07543265
  ), nrow = 4, byrow = TRUE)  
  
  X_setosa_train <- mvrnorm(n_train %/% 3, mu_setosa, setosa_cov)
  X_setosa_val <- mvrnorm(n_val %/% 3, mu_setosa, setosa_cov)
  X_setosa_test <- mvrnorm(n_test %/% 3, mu_setosa, setosa_cov) 
  
  X_versicolor_train <- mvrnorm(n_train %/% 3, mu_versicolor, versicolor_cov)
  X_versicolor_val <- mvrnorm(n_val %/% 3, mu_versicolor, versicolor_cov)
  X_versicolor_test <- mvrnorm(n_test %/% 3, mu_versicolor, versicolor_cov) 
  
  X_virginica_train <- mvrnorm(n_train %/% 3, mu_virginica, virginica_cov)
  X_virginica_val <- mvrnorm(n_val %/% 3, mu_virginica, virginica_cov)
  X_virginica_test <- mvrnorm(n_test %/% 3, mu_virginica, virginica_cov)
  
  X_train <- rbind(X_setosa_train, X_versicolor_train, X_virginica_train)
  y_train <- c(rep(0, n_train %/% 3), rep(1, n_train %/% 3), rep(2, n_train %/% 3))
  
  X_val <- rbind(X_setosa_val, X_versicolor_val, X_virginica_val)
  y_val <- c(rep(0, n_val %/% 3), rep(1, n_val %/% 3), rep(2, n_val %/% 3))
  
  X_test <- rbind(X_setosa_test, X_versicolor_test, X_virginica_test)
  y_test <- c(rep(0, n_test %/% 3), rep(1, n_test %/% 3), rep(2, n_test %/% 3))
  
  X_train <- X_train + rnorm(length(X_train), 0, noise_level)
  X_val <- X_val + rnorm(length(X_val), 0, noise_level)
  X_test <- X_test + rnorm(length(X_test), 0, noise_level)
  
  list(
    train = data.frame(X_train, y_train = as.factor(y_train)),
    val = data.frame(X_val, y_val = as.factor(y_val)),
    test = data.frame(X_test, y_test = as.factor(y_test))
  )
}

hardness_values <- c(0.2, 1, 2)
noise_levels <- c(0.2, 1, 2)
training_sizes <- c(100, 1000, 10000)
validation_size <- 1000
test_size <- 1000

for (training_size in training_sizes){
    for (noise_level in noise_levels) {
        for (hardness in hardness_values) {
            synthetic_data <- generate_synthetic_data(training_size, validation_size, test_size, noise_level, hardness)
            plot <-ggpairs(synthetic_data$train, aes(color = y_train)) +
            ggtitle(paste("Pair Plot of Synthetic Training Data (Noise:", noise_level, ", Hardness:", hardness, ")"))
            print(plot)
  }
}
}

```

## Neural Network

```{r}

library(nnet)

train_nn <<- function(train_data, size = 1, maxit = 200, decay = 0.001) {

  train_data$y_train <- as.factor(train_data$y_train)

  model <- nnet(y_train ~ ., 
                data = train_data, 
                size = size, 
                maxit = maxit, 
                decay = decay, 
                linout = FALSE)

  return(model)
}

test_nn <<- function(best_model, test_data){

    y_pred = predict(best_model, newdata = test_data[, -ncol(test_data)], type = "class")

    accuracy = accuracy <- mean(y_pred == test_data[, ncol(test_data)])
    
    cat(sprintf("Test Accuracy: %.4f\n", accuracy))
    
    return(accuracy)
}
```

## Genetic Algorithm


## Evolution Strategy


## Run

```{r}

library(tictoc)

# ---------- DATA PARAMETERS ----------

hardness_values <- c(0.2, 1, 2)
noise_levels <- c(0.2, 1, 2)
training_sizes <- c(100, 1000, 10000)
validation_size <- 1000
test_size <- 1000

# ---------- RUN PARAMETERS ----------

sizes <- c(1, 5, 10)
maxits <- c(100, 200, 300) 
training_functions  <- c("train_nn")


# ---------- RESULT STRUCTURE ----------

results <- data.frame(
  hardness = numeric(),
  noise = numeric(),
  training_size = numeric(),
  size = numeric(),
  maxit = numeric(),
  training_function = character(),
  test_accuracy = numeric(),
  training_time = numeric(),
  stringsAsFactors = FALSE
)

# ---------- EVALUATION ----------

for (hardness in hardness_values) {
  for (noise in noise_levels) {
    for (training_size in training_sizes) {

      data <- generate_synthetic_data(training_size, validation_size, test_size, noise, hardness)
      
      train_data <- data$train
      val_data <- data$val
      test_data <- data$test

      for (size in sizes) {
        for (maxit in maxits) {
          for (training_function in training_functions) {
            
            # Retrieve the training function by name
            func <- get(training_function)
            
            # Measure training time using tic and toc
            tic() 
            model <- func(train_data, size, maxit)
            training_time <- toc(quiet = TRUE)$toc 
            
            # Test accuracy
            test_accuracy <- test_nn(model, test_data)
            
            # Store result
            results <- rbind(results, data.frame(
              hardness = hardness,
              noise = noise,
              training_size = training_size,
              size = size,
              maxit = maxit,
              training_function = training_function,
              test_accuracy = test_accuracy,
              training_time = training_time
            ))
          }
        }
      }
    }
  }
}

# Identify the fastest and most accurate runs
fastest_run <- results[which.min(results$training_time), ]
most_accurate_run <- results[which.max(results$test_accuracy), ]

# Print results
print("Fastest Run:")
print(fastest_run)

print("Most Accurate Run:")
print(most_accurate_run)
```

## Evaluation & results

```{r}


```

